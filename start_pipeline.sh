#!/bin/bash

# ğŸš€ CryptoBridge Complete Data Pipeline Startup
# Enterprise Medallion Architeecho "ğŸ­ Data Lake Architecture:"
echo "   ğŸ¥‰ Bronze Layer:  Raw data ingestion (Kafka to HDFS)"
echo "   ğŸ¥ˆ Silver Layer:  Data cleaning & enrichment"
echo "   ğŸ¥‡ Gold Layer:    Business analytics & KPIs"e with Real-Time Streaming & Batch Processing

echo "ğŸ­ Starting CryptoBridge Complete Data Pipeline"
echo "==============================================="
echo "ğŸ—ï¸ Medallion Architecture: Bronze â†’ Silver â†’ Gold"
echo "âš¡ Real-Time Streaming + Batch Processing"
echo "ğŸ“Š Enterprise Analytics & Business Intelligence"
echo "==============================================="

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker first."
    exit 1
fi

# Start Docker Compose services (including new data lake services)
echo "ğŸ“¦ Starting all Docker services..."
echo "   ğŸ”„ Kafka + Zookeeper (Streaming)"
echo "   ğŸ—„ï¸ HDFS (Distributed Storage)"
echo "   âš¡ Spark (Processing Engine)"
echo "   ğŸ“Š ClickHouse (Analytics Database)"
docker compose up -d

# Wait for services to be ready (extended time for HDFS)
echo "â³ Waiting for services to initialize..."
echo "   ğŸ“ Core services: 30 seconds"
sleep 30

echo "   ğŸ“ HDFS NameNode initialization: 20 seconds"
sleep 20

echo "   ğŸ“ Spark cluster formation: 15 seconds"
sleep 15

# Check critical services
echo "ğŸ” Checking critical services..."

# Check HDFS NameNode
if curl -s http://localhost:9870 > /dev/null; then
    echo "   âœ… HDFS NameNode: Ready"
else
    echo "   âš ï¸ HDFS NameNode: Starting up..."
fi

# Check Spark Master
if curl -s http://localhost:8080 > /dev/null; then
    echo "   âœ… Spark Master: Ready"
else
    echo "   âš ï¸ Spark Master: Starting up..."
fi

# Check Kafka
if docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list > /dev/null 2>&1; then
    echo "   âœ… Kafka: Ready"
else
    echo "   âš ï¸ Kafka: Starting up..."
fi

# Setup Kafka topics
echo "ğŸ“¡ Setting up Kafka topics..."
python3 scripts/setup_kafka_topics.py

# Setup HDFS directories for data lake
echo "ğŸ—‚ï¸ Setting up HDFS directory structure..."
echo "   ğŸ“ Creating Bronze layer directories..."
docker exec namenode hdfs dfs -mkdir -p /crypto-bridge-datalake/bronze
docker exec namenode hdfs dfs -mkdir -p /crypto-bridge-datalake/silver  
docker exec namenode hdfs dfs -mkdir -p /crypto-bridge-datalake/gold
docker exec namenode hdfs dfs -mkdir -p /crypto-bridge-datalake/checkpoints

echo "   ğŸ“ Setting permissions..."
docker exec namenode hdfs dfs -chmod -R 777 /crypto-bridge-datalake

echo "   âœ… Data lake directory structure ready"

# Show comprehensive service status
echo "ğŸ“Š Complete Service Status:"
echo "=========================================="
docker compose ps

echo ""
echo "ğŸ¯ Pipeline Setup Complete!"
echo "=========================================="
echo "ğŸ”— Access Points:"
echo "   ğŸ“¡ Kafka UI:      http://localhost:8090"
echo "   âš¡ Spark Master:  http://localhost:8080"
echo "   ğŸ—„ï¸ HDFS NameNode: http://localhost:9870"
echo "   ğŸ“Š ClickHouse:    http://localhost:8123"
echo ""
echo "ï¿½ Data Lake Architecture:"
echo "   ğŸ¥‰ Bronze Layer:  Raw data ingestion (Kafka â†’ HDFS)"
echo "   ğŸ¥ˆ Silver Layer:  Data cleaning & enrichment"
echo "   ğŸ¥‡ Gold Layer:    Business analytics & KPIs"
echo ""
echo "ğŸš€ Quick Start Options:"
echo "=========================================="
echo "   Option A - Complete Medallion Pipeline:"
echo "     python3 scripts/data_lake_orchestrator.py"
echo ""
echo "   Option B - Individual Components:"
echo "     1. Producer:  python3 scripts/kafka_transaction_producer.py"
echo "     2. Consumer:  python3 scripts/kafka_transaction_consumer.py"
echo "     3. Bronze:    python3 scripts/bronze_layer_processor.py"
echo "     4. Silver:    python3 scripts/silver_layer_processor.py"
echo "     5. Gold:      python3 scripts/gold_layer_processor.py"
echo ""
echo "ğŸ“Š Monitoring & Management:"
echo "   â€¢ Monitor data lake files: http://localhost:9870"
echo "   â€¢ Track Spark jobs: http://localhost:8080"
echo "   â€¢ View Kafka topics: http://localhost:8090"
echo "   â€¢ Query analytics: http://localhost:8123"
echo ""
echo "ğŸ›‘ To stop all services: docker compose down"